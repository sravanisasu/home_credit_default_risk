MlflowException: Failed to enforce schema of data '[[0.         0.         0.         1.         0.         0.00151187
  0.09028652 0.09003159 0.07744108 0.25632114 0.11116122 0.96443725
  0.85214008 0.70543282 0.0989011  1.         1.         0.
  1.         1.         0.         0.         0.5        0.5
  0.43478261 0.         0.         0.         0.         0.
  0.         0.07221502 0.30754227 0.15505445 0.0247     0.0369
  0.9722     0.6192     0.0143     0.         0.069      0.0833
  0.125      0.0369     0.0202     0.019      0.         0.
  0.0252     0.0383     0.9722     0.6341     0.0144     0.
  0.069      0.0833     0.125      0.0377     0.022      0.0198
  0.         0.         0.025      0.0369     0.9722     0.6243
  0.0144     0.         0.069      0.0833     0.125      0.0375
  0.0205     0.0193     0.         0.         0.0149     0.00574713
  0.05882353 0.00581395 0.08333333 0.73578751 0.         1.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.04
  0.         1.         0.         0.         0.         0.
  0.         0.         0.         1.         0.         0.
  0.         0.         0.         0.         0.         1.
  0.         0.         0.         0.         1.         0.
  0.         0.         1.         0.         0.         0.
  1.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         1.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         1.
  0.         0.         0.         0.         0.         1.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  1.         0.         1.         0.         0.         0.
  0.         0.         0.         0.         1.         0.
  1.         0.         0.        ]]' with schema '['SK_ID_CURR': long (required), 'NAME_CONTRACT_TYPE': string (required), 'CODE_GENDER': string (required), 'FLAG_OWN_CAR': string (required), 'FLAG_OWN_REALTY': string (required), 'CNT_CHILDREN': long (required), 'AMT_INCOME_TOTAL': double (required), 'AMT_CREDIT': double (required), 'AMT_ANNUITY': double (required), 'AMT_GOODS_PRICE': double (required), 'NAME_TYPE_SUITE': string (required), 'NAME_INCOME_TYPE': string (required), 'NAME_EDUCATION_TYPE': string (required), 'NAME_FAMILY_STATUS': string (required), 'NAME_HOUSING_TYPE': string (required), 'REGION_POPULATION_RELATIVE': double (required), 'DAYS_BIRTH': long (required), 'DAYS_EMPLOYED': long (required), 'DAYS_REGISTRATION': double (required), 'DAYS_ID_PUBLISH': long (required), 'OWN_CAR_AGE': double (required), 'FLAG_MOBIL': long (required), 'FLAG_EMP_PHONE': long (required), 'FLAG_WORK_PHONE': long (required), 'FLAG_CONT_MOBILE': long (required), 'FLAG_PHONE': long (required), 'FLAG_EMAIL': long (required), 'OCCUPATION_TYPE': string (required), 'CNT_FAM_MEMBERS': double (required), 'REGION_RATING_CLIENT': long (required), 'REGION_RATING_CLIENT_W_CITY': long (required), 'WEEKDAY_APPR_PROCESS_START': string (required), 'HOUR_APPR_PROCESS_START': long (required), 'REG_REGION_NOT_LIVE_REGION': long (required), 'REG_REGION_NOT_WORK_REGION': long (required), 'LIVE_REGION_NOT_WORK_REGION': long (required), 'REG_CITY_NOT_LIVE_CITY': long (required), 'REG_CITY_NOT_WORK_CITY': long (required), 'LIVE_CITY_NOT_WORK_CITY': long (required), 'ORGANIZATION_TYPE': string (required), 'EXT_SOURCE_1': double (required), 'EXT_SOURCE_2': double (required), 'EXT_SOURCE_3': double (required), 'APARTMENTS_AVG': double (required), 'BASEMENTAREA_AVG': double (required), 'YEARS_BEGINEXPLUATATION_AVG': double (required), 'YEARS_BUILD_AVG': double (required), 'COMMONAREA_AVG': double (required), 'ELEVATORS_AVG': double (required), 'ENTRANCES_AVG': double (required), 'FLOORSMAX_AVG': double (required), 'FLOORSMIN_AVG': double (required), 'LANDAREA_AVG': double (required), 'LIVINGAPARTMENTS_AVG': double (required), 'LIVINGAREA_AVG': double (required), 'NONLIVINGAPARTMENTS_AVG': double (required), 'NONLIVINGAREA_AVG': double (required), 'APARTMENTS_MODE': double (required), 'BASEMENTAREA_MODE': double (required), 'YEARS_BEGINEXPLUATATION_MODE': double (required), 'YEARS_BUILD_MODE': double (required), 'COMMONAREA_MODE': double (required), 'ELEVATORS_MODE': double (required), 'ENTRANCES_MODE': double (required), 'FLOORSMAX_MODE': double (required), 'FLOORSMIN_MODE': double (required), 'LANDAREA_MODE': double (required), 'LIVINGAPARTMENTS_MODE': double (required), 'LIVINGAREA_MODE': double (required), 'NONLIVINGAPARTMENTS_MODE': double (required), 'NONLIVINGAREA_MODE': double (required), 'APARTMENTS_MEDI': double (required), 'BASEMENTAREA_MEDI': double (required), 'YEARS_BEGINEXPLUATATION_MEDI': double (required), 'YEARS_BUILD_MEDI': double (required), 'COMMONAREA_MEDI': double (required), 'ELEVATORS_MEDI': double (required), 'ENTRANCES_MEDI': double (required), 'FLOORSMAX_MEDI': double (required), 'FLOORSMIN_MEDI': double (required), 'LANDAREA_MEDI': double (required), 'LIVINGAPARTMENTS_MEDI': double (required), 'LIVINGAREA_MEDI': double (required), 'NONLIVINGAPARTMENTS_MEDI': double (required), 'NONLIVINGAREA_MEDI': double (required), 'FONDKAPREMONT_MODE': string (required), 'HOUSETYPE_MODE': string (required), 'TOTALAREA_MODE': double (required), 'WALLSMATERIAL_MODE': string (required), 'EMERGENCYSTATE_MODE': string (required), 'OBS_30_CNT_SOCIAL_CIRCLE': double (required), 'DEF_30_CNT_SOCIAL_CIRCLE': double (required), 'OBS_60_CNT_SOCIAL_CIRCLE': double (required), 'DEF_60_CNT_SOCIAL_CIRCLE': double (required), 'DAYS_LAST_PHONE_CHANGE': double (required), 'FLAG_DOCUMENT_2': long (required), 'FLAG_DOCUMENT_3': long (required), 'FLAG_DOCUMENT_4': long (required), 'FLAG_DOCUMENT_5': long (required), 'FLAG_DOCUMENT_6': long (required), 'FLAG_DOCUMENT_7': long (required), 'FLAG_DOCUMENT_8': long (required), 'FLAG_DOCUMENT_9': long (required), 'FLAG_DOCUMENT_10': long (required), 'FLAG_DOCUMENT_11': long (required), 'FLAG_DOCUMENT_12': long (required), 'FLAG_DOCUMENT_13': long (required), 'FLAG_DOCUMENT_14': long (required), 'FLAG_DOCUMENT_15': long (required), 'FLAG_DOCUMENT_16': long (required), 'FLAG_DOCUMENT_17': long (required), 'FLAG_DOCUMENT_18': long (required), 'FLAG_DOCUMENT_19': long (required), 'FLAG_DOCUMENT_20': long (required), 'FLAG_DOCUMENT_21': long (required), 'AMT_REQ_CREDIT_BUREAU_HOUR': double (required), 'AMT_REQ_CREDIT_BUREAU_DAY': double (required), 'AMT_REQ_CREDIT_BUREAU_WEEK': double (required), 'AMT_REQ_CREDIT_BUREAU_MON': double (required), 'AMT_REQ_CREDIT_BUREAU_QRT': double (required), 'AMT_REQ_CREDIT_BUREAU_YEAR': double (required)]'. Error: Model is missing inputs ['SK_ID_CURR', 'NAME_CONTRACT_TYPE', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'CNT_CHILDREN', 'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'NAME_TYPE_SUITE', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'REGION_POPULATION_RELATIVE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'OWN_CAR_AGE', 'FLAG_MOBIL', 'FLAG_EMP_PHONE', 'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE', 'FLAG_PHONE', 'FLAG_EMAIL', 'OCCUPATION_TYPE', 'CNT_FAM_MEMBERS', 'REGION_RATING_CLIENT', 'REGION_RATING_CLIENT_W_CITY', 'WEEKDAY_APPR_PROCESS_START', 'HOUR_APPR_PROCESS_START', 'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION', 'LIVE_REGION_NOT_WORK_REGION', 'REG_CITY_NOT_LIVE_CITY', 'REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY', 'ORGANIZATION_TYPE', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'APARTMENTS_AVG', 'BASEMENTAREA_AVG', 'YEARS_BEGINEXPLUATATION_AVG', 'YEARS_BUILD_AVG', 'COMMONAREA_AVG', 'ELEVATORS_AVG', 'ENTRANCES_AVG', 'FLOORSMAX_AVG', 'FLOORSMIN_AVG', 'LANDAREA_AVG', 'LIVINGAPARTMENTS_AVG', 'LIVINGAREA_AVG', 'NONLIVINGAPARTMENTS_AVG', 'NONLIVINGAREA_AVG', 'APARTMENTS_MODE', 'BASEMENTAREA_MODE', 'YEARS_BEGINEXPLUATATION_MODE', 'YEARS_BUILD_MODE', 'COMMONAREA_MODE', 'ELEVATORS_MODE', 'ENTRANCES_MODE', 'FLOORSMAX_MODE', 'FLOORSMIN_MODE', 'LANDAREA_MODE', 'LIVINGAPARTMENTS_MODE', 'LIVINGAREA_MODE', 'NONLIVINGAPARTMENTS_MODE', 'NONLIVINGAREA_MODE', 'APARTMENTS_MEDI', 'BASEMENTAREA_MEDI', 'YEARS_BEGINEXPLUATATION_MEDI', 'YEARS_BUILD_MEDI', 'COMMONAREA_MEDI', 'ELEVATORS_MEDI', 'ENTRANCES_MEDI', 'FLOORSMAX_MEDI', 'FLOORSMIN_MEDI', 'LANDAREA_MEDI', 'LIVINGAPARTMENTS_MEDI', 'LIVINGAREA_MEDI', 'NONLIVINGAPARTMENTS_MEDI', 'NONLIVINGAREA_MEDI', 'FONDKAPREMONT_MODE', 'HOUSETYPE_MODE', 'TOTALAREA_MODE', 'WALLSMATERIAL_MODE', 'EMERGENCYSTATE_MODE', 'OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE', 'DAYS_LAST_PHONE_CHANGE', 'FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3', 'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6', 'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12', 'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21', 'AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_WEEK', 'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_QRT', 'AMT_REQ_CREDIT_BUREAU_YEAR']. Note that there were extra inputs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242]
---------------------------------------------------------------------------
MlflowException                           Traceback (most recent call last)
File /local_disk0/.ephemeral_nfs/envs/pythonEnv-45e6e4c1-544c-4087-91cd-dd546c61c60a/lib/python3.10/site-packages/mlflow/pyfunc/__init__.py:689, in _validate_prediction_input(data, params, input_schema, params_schema, flavor)
    688 try:
--> 689     data = _enforce_schema(data, input_schema, flavor)
    690 except Exception as e:
    691     # Include error in message for backwards compatibility

File /local_disk0/.ephemeral_nfs/envs/pythonEnv-45e6e4c1-544c-4087-91cd-dd546c61c60a/lib/python3.10/site-packages/mlflow/models/utils.py:1166, in _enforce_schema(pf_input, input_schema, flavor)
   1165         message += f" Note that there were extra inputs: {extra_cols}"
-> 1166     raise MlflowException(message)
   1167 if extra_cols:

MlflowException: Model is missing inputs ['SK_ID_CURR', 'NAME_CONTRACT_TYPE', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'CNT_CHILDREN', 'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'NAME_TYPE_SUITE', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'REGION_POPULATION_RELATIVE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'OWN_CAR_AGE', 'FLAG_MOBIL', 'FLAG_EMP_PHONE', 'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE', 'FLAG_PHONE', 'FLAG_EMAIL', 'OCCUPATION_TYPE', 'CNT_FAM_MEMBERS', 'REGION_RATING_CLIENT', 'REGION_RATING_CLIENT_W_CITY', 'WEEKDAY_APPR_PROCESS_START', 'HOUR_APPR_PROCESS_START', 'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION', 'LIVE_REGION_NOT_WORK_REGION', 'REG_CITY_NOT_LIVE_CITY', 'REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY', 'ORGANIZATION_TYPE', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'APARTMENTS_AVG', 'BASEMENTAREA_AVG', 'YEARS_BEGINEXPLUATATION_AVG', 'YEARS_BUILD_AVG', 'COMMONAREA_AVG', 'ELEVATORS_AVG', 'ENTRANCES_AVG', 'FLOORSMAX_AVG', 'FLOORSMIN_AVG', 'LANDAREA_AVG', 'LIVINGAPARTMENTS_AVG', 'LIVINGAREA_AVG', 'NONLIVINGAPARTMENTS_AVG', 'NONLIVINGAREA_AVG', 'APARTMENTS_MODE', 'BASEMENTAREA_MODE', 'YEARS_BEGINEXPLUATATION_MODE', 'YEARS_BUILD_MODE', 'COMMONAREA_MODE', 'ELEVATORS_MODE', 'ENTRANCES_MODE', 'FLOORSMAX_MODE', 'FLOORSMIN_MODE', 'LANDAREA_MODE', 'LIVINGAPARTMENTS_MODE', 'LIVINGAREA_MODE', 'NONLIVINGAPARTMENTS_MODE', 'NONLIVINGAREA_MODE', 'APARTMENTS_MEDI', 'BASEMENTAREA_MEDI', 'YEARS_BEGINEXPLUATATION_MEDI', 'YEARS_BUILD_MEDI', 'COMMONAREA_MEDI', 'ELEVATORS_MEDI', 'ENTRANCES_MEDI', 'FLOORSMAX_MEDI', 'FLOORSMIN_MEDI', 'LANDAREA_MEDI', 'LIVINGAPARTMENTS_MEDI', 'LIVINGAREA_MEDI', 'NONLIVINGAPARTMENTS_MEDI', 'NONLIVINGAREA_MEDI', 'FONDKAPREMONT_MODE', 'HOUSETYPE_MODE', 'TOTALAREA_MODE', 'WALLSMATERIAL_MODE', 'EMERGENCYSTATE_MODE', 'OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE', 'DAYS_LAST_PHONE_CHANGE', 'FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3', 'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6', 'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12', 'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21', 'AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_WEEK', 'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_QRT', 'AMT_REQ_CREDIT_BUREAU_YEAR']. Note that there were extra inputs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242]

During handling of the above exception, another exception occurred:

MlflowException                           Traceback (most recent call last)
File <command-480144306555780>, line 61
     56 # Proceed with prediction
     57 cm = CustomModel(
     58     model, loaded_le_flag_own_car, loaded_le_flag_own_realty, 
     59     loaded_le_name_contract_type, features_list, imputer, scaler
     60 )
---> 61 cm.predict(context=None, model_input=predictions_df)

File <command-1822611895488555>, line 48, in CustomModel.predict(self, context, model_input)
     45 print(type(model_input))
     47 model_input = self.pre_process(model_input)
---> 48 return self.model.predict(model_input).tolist()

File /local_disk0/.ephemeral_nfs/envs/pythonEnv-45e6e4c1-544c-4087-91cd-dd546c61c60a/lib/python3.10/site-packages/mlflow/pyfunc/__init__.py:767, in PyFuncModel.predict(self, data, params)
    765 if schema := _get_dependencies_schema_from_model(self._model_meta):
    766     context.update(**schema)
--> 767 return self._predict(data, params)

File /local_disk0/.ephemeral_nfs/envs/pythonEnv-45e6e4c1-544c-4087-91cd-dd546c61c60a/lib/python3.10/site-packages/mlflow/pyfunc/__init__.py:800, in PyFuncModel._predict(self, data, params)
    798 self.input_schema = self.metadata.get_input_schema()
    799 self.params_schema = self.metadata.get_params_schema()
--> 800 data, params = _validate_prediction_input(
    801     data, params, self.input_schema, self.params_schema, self.loader_module
    802 )
    803 params_arg = inspect.signature(self._predict_fn).parameters.get("params")
    804 if params_arg and params_arg.kind != inspect.Parameter.VAR_KEYWORD:

File /local_disk0/.ephemeral_nfs/envs/pythonEnv-45e6e4c1-544c-4087-91cd-dd546c61c60a/lib/python3.10/site-packages/mlflow/pyfunc/__init__.py:692, in _validate_prediction_input(data, params, input_schema, params_schema, flavor)
    689         data = _enforce_schema(data, input_schema, flavor)
    690     except Exception as e:
    691         # Include error in message for backwards compatibility
--> 692         raise MlflowException.invalid_parameter_value(
    693             f"Failed to enforce schema of data '{data}' "
    694             f"with schema '{input_schema}'. "
    695             f"Error: {e}",
    696         )
    697 params = _enforce_params_schema(params, params_schema)
    698 if HAS_PYSPARK and isinstance(data, SparkDataFrame):

MlflowException: Failed to enforce schema of data '[[0.         0.         0.         1.         0.         0.00151187
  0.09028652 0.09003159 0.07744108 0.25632114 0.11116122 0.96443725
  0.85214008 0.70543282 0.0989011  1.         1.         0.
  1.         1.         0.         0.         0.5        0.5
  0.43478261 0.         0.         0.         0.         0.
  0.         0.07221502 0.30754227 0.15505445 0.0247     0.0369
  0.9722     0.6192     0.0143     0.         0.069      0.0833
  0.125      0.0369     0.0202     0.019      0.         0.
  0.0252     0.0383     0.9722     0.6341     0.0144     0.
  0.069      0.0833     0.125      0.0377     0.022      0.0198
  0.         0.         0.025      0.0369     0.9722     0.6243
  0.0144     0.         0.069      0.0833     0.125      0.0375
  0.0205     0.0193     0.         0.         0.0149     0.00574713
  0.05882353 0.00581395 0.08333333 0.73578751 0.         1.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.04
  0.         1.         0.         0.         0.         0.
  0.         0.         0.         1.         0.         0.
  0.         0.         0.         0.         0.         1.
  0.         0.         0.         0.         1.         0.
  0.         0.         1.         0.         0.         0.
  1.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         1.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         1.
  0.         0.         0.         0.         0.         1.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  1.         0.         1.         0.         0.         0.
  0.         0.         0.         0.         1.         0.
  1.         0.         0.        ]]' with schema '['SK_ID_CURR': long (required), 'NAME_CONTRACT_TYPE': string (required), 'CODE_GENDER': string (required), 'FLAG_OWN_CAR': string (required), 'FLAG_OWN_REALTY': string (required), 'CNT_CHILDREN': long (required), 'AMT_INCOME_TOTAL': double (required), 'AMT_CREDIT': double (required), 'AMT_ANNUITY': double (required), 'AMT_GOODS_PRICE': double (required), 'NAME_TYPE_SUITE': string (required), 'NAME_INCOME_TYPE': string (required), 'NAME_EDUCATION_TYPE': string (required), 'NAME_FAMILY_STATUS': string (required), 'NAME_HOUSING_TYPE': string (required), 'REGION_POPULATION_RELATIVE': double (required), 'DAYS_BIRTH': long (required), 'DAYS_EMPLOYED': long (required), 'DAYS_REGISTRATION': double (required), 'DAYS_ID_PUBLISH': long (required), 'OWN_CAR_AGE': double (required), 'FLAG_MOBIL': long (required), 'FLAG_EMP_PHONE': long (required), 'FLAG_WORK_PHONE': long (required), 'FLAG_CONT_MOBILE': long (required), 'FLAG_PHONE': long (required), 'FLAG_EMAIL': long (required), 'OCCUPATION_TYPE': string (required), 'CNT_FAM_MEMBERS': double (required), 'REGION_RATING_CLIENT': long (required), 'REGION_RATING_CLIENT_W_CITY': long (required), 'WEEKDAY_APPR_PROCESS_START': string (required), 'HOUR_APPR_PROCESS_START': long (required), 'REG_REGION_NOT_LIVE_REGION': long (required), 'REG_REGION_NOT_WORK_REGION': long (required), 'LIVE_REGION_NOT_WORK_REGION': long (required), 'REG_CITY_NOT_LIVE_CITY': long (required), 'REG_CITY_NOT_WORK_CITY': long (required), 'LIVE_CITY_NOT_WORK_CITY': long (required), 'ORGANIZATION_TYPE': string (required), 'EXT_SOURCE_1': double (required), 'EXT_SOURCE_2': double (required), 'EXT_SOURCE_3': double (required), 'APARTMENTS_AVG': double (required), 'BASEMENTAREA_AVG': double (required), 'YEARS_BEGINEXPLUATATION_AVG': double (required), 'YEARS_BUILD_AVG': double (required), 'COMMONAREA_AVG': double (required), 'ELEVATORS_AVG': double (required), 'ENTRANCES_AVG': double (required), 'FLOORSMAX_AVG': double (required), 'FLOORSMIN_AVG': double (required), 'LANDAREA_AVG': double (required), 'LIVINGAPARTMENTS_AVG': double (required), 'LIVINGAREA_AVG': double (required), 'NONLIVINGAPARTMENTS_AVG': double (required), 'NONLIVINGAREA_AVG': double (required), 'APARTMENTS_MODE': double (required), 'BASEMENTAREA_MODE': double (required), 'YEARS_BEGINEXPLUATATION_MODE': double (required), 'YEARS_BUILD_MODE': double (required), 'COMMONAREA_MODE': double (required), 'ELEVATORS_MODE': double (required), 'ENTRANCES_MODE': double (required), 'FLOORSMAX_MODE': double (required), 'FLOORSMIN_MODE': double (required), 'LANDAREA_MODE': double (required), 'LIVINGAPARTMENTS_MODE': double (required), 'LIVINGAREA_MODE': double (required), 'NONLIVINGAPARTMENTS_MODE': double (required), 'NONLIVINGAREA_MODE': double (required), 'APARTMENTS_MEDI': double (required), 'BASEMENTAREA_MEDI': double (required), 'YEARS_BEGINEXPLUATATION_MEDI': double (required), 'YEARS_BUILD_MEDI': double (required), 'COMMONAREA_MEDI': double (required), 'ELEVATORS_MEDI': double (required), 'ENTRANCES_MEDI': double (required), 'FLOORSMAX_MEDI': double (required), 'FLOORSMIN_MEDI': double (required), 'LANDAREA_MEDI': double (required), 'LIVINGAPARTMENTS_MEDI': double (required), 'LIVINGAREA_MEDI': double (required), 'NONLIVINGAPARTMENTS_MEDI': double (required), 'NONLIVINGAREA_MEDI': double (required), 'FONDKAPREMONT_MODE': string (required), 'HOUSETYPE_MODE': string (required), 'TOTALAREA_MODE': double (required), 'WALLSMATERIAL_MODE': string (required), 'EMERGENCYSTATE_MODE': string (required), 'OBS_30_CNT_SOCIAL_CIRCLE': double (required), 'DEF_30_CNT_SOCIAL_CIRCLE': double (required), 'OBS_60_CNT_SOCIAL_CIRCLE': double (required), 'DEF_60_CNT_SOCIAL_CIRCLE': double (required), 'DAYS_LAST_PHONE_CHANGE': double (required), 'FLAG_DOCUMENT_2': long (required), 'FLAG_DOCUMENT_3': long (required), 'FLAG_DOCUMENT_4': long (required), 'FLAG_DOCUMENT_5': long (required), 'FLAG_DOCUMENT_6': long (required), 'FLAG_DOCUMENT_7': long (required), 'FLAG_DOCUMENT_8': long (required), 'FLAG_DOCUMENT_9': long (required), 'FLAG_DOCUMENT_10': long (required), 'FLAG_DOCUMENT_11': long (required), 'FLAG_DOCUMENT_12': long (required), 'FLAG_DOCUMENT_13': long (required), 'FLAG_DOCUMENT_14': long (required), 'FLAG_DOCUMENT_15': long (required), 'FLAG_DOCUMENT_16': long (required), 'FLAG_DOCUMENT_17': long (required), 'FLAG_DOCUMENT_18': long (required), 'FLAG_DOCUMENT_19': long (required), 'FLAG_DOCUMENT_20': long (required), 'FLAG_DOCUMENT_21': long (required), 'AMT_REQ_CREDIT_BUREAU_HOUR': double (required), 'AMT_REQ_CREDIT_BUREAU_DAY': double (required), 'AMT_REQ_CREDIT_BUREAU_WEEK': double (required), 'AMT_REQ_CREDIT_BUREAU_MON': double (required), 'AMT_REQ_CREDIT_BUREAU_QRT': double (required), 'AMT_REQ_CREDIT_BUREAU_YEAR': double (required)]'. Error: Model is missing inputs ['SK_ID_CURR', 'NAME_CONTRACT_TYPE', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'CNT_CHILDREN', 'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'NAME_TYPE_SUITE', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'REGION_POPULATION_RELATIVE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'OWN_CAR_AGE', 'FLAG_MOBIL', 'FLAG_EMP_PHONE', 'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE', 'FLAG_PHONE', 'FLAG_EMAIL', 'OCCUPATION_TYPE', 'CNT_FAM_MEMBERS', 'REGION_RATING_CLIENT', 'REGION_RATING_CLIENT_W_CITY', 'WEEKDAY_APPR_PROCESS_START', 'HOUR_APPR_PROCESS_START', 'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION', 'LIVE_REGION_NOT_WORK_REGION', 'REG_CITY_NOT_LIVE_CITY', 'REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY', 'ORGANIZATION_TYPE', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'APARTMENTS_AVG', 'BASEMENTAREA_AVG', 'YEARS_BEGINEXPLUATATION_AVG', 'YEARS_BUILD_AVG', 'COMMONAREA_AVG', 'ELEVATORS_AVG', 'ENTRANCES_AVG', 'FLOORSMAX_AVG', 'FLOORSMIN_AVG', 'LANDAREA_AVG', 'LIVINGAPARTMENTS_AVG', 'LIVINGAREA_AVG', 'NONLIVINGAPARTMENTS_AVG', 'NONLIVINGAREA_AVG', 'APARTMENTS_MODE', 'BASEMENTAREA_MODE', 'YEARS_BEGINEXPLUATATION_MODE', 'YEARS_BUILD_MODE', 'COMMONAREA_MODE', 'ELEVATORS_MODE', 'ENTRANCES_MODE', 'FLOORSMAX_MODE', 'FLOORSMIN_MODE', 'LANDAREA_MODE', 'LIVINGAPARTMENTS_MODE', 'LIVINGAREA_MODE', 'NONLIVINGAPARTMENTS_MODE', 'NONLIVINGAREA_MODE', 'APARTMENTS_MEDI', 'BASEMENTAREA_MEDI', 'YEARS_BEGINEXPLUATATION_MEDI', 'YEARS_BUILD_MEDI', 'COMMONAREA_MEDI', 'ELEVATORS_MEDI', 'ENTRANCES_MEDI', 'FLOORSMAX_MEDI', 'FLOORSMIN_MEDI', 'LANDAREA_MEDI', 'LIVINGAPARTMENTS_MEDI', 'LIVINGAREA_MEDI', 'NONLIVINGAPARTMENTS_MEDI', 'NONLIVINGAREA_MEDI', 'FONDKAPREMONT_MODE', 'HOUSETYPE_MODE', 'TOTALAREA_MODE', 'WALLSMATERIAL_MODE', 'EMERGENCYSTATE_MODE', 'OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE', 'DAYS_LAST_PHONE_CHANGE', 'FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3', 'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6', 'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12', 'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21', 'AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_WEEK', 'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_QRT', 'AMT_REQ_CREDIT_BUREAU_YEAR']. Note that there were extra inputs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242]




































Exception: Request failed with status 400, {"error_code": "BAD_REQUEST", "message": "Encountered an unexpected error while evaluating the model. Verify that the input is compatible with the model for inference. Error '/tmp/build/80754af9/python_1599203911753/work/Objects/listobject.c:353: bad argument to internal function'", "stack_trace": "Traceback (most recent call last):\n  File \"/opt/conda/envs/mlflow-env/lib/python3.8/site-packages/mlflowserving/scoring_server/__init__.py\", line 676, in transformation\n    (raw_predictions, databricks_output, fs_metrics) = _score_model(\n  File \"/opt/conda/envs/mlflow-env/lib/python3.8/site-packages/mlflowserving/scoring_server/__init__.py\", line 431, in _score_model\n    prediction, fs_metrics = score_model_maybe_with_fs_metrics(model, data, params)\n  File \"/opt/conda/envs/mlflow-env/lib/python3.8/site-packages/mlflowserving/scoring_server/scoring_server_utils.py\", line 595, in score_model_maybe_with_fs_metrics\n    return (score_pyfunc_model(model, data, params), None)\n  File \"/opt/conda/envs/mlflow-env/lib/python3.8/site-packages/mlflowserving/scoring_server/scoring_server_utils.py\", line 600, in score_pyfunc_model\n    return model.predict(data, params=params)\n  File \"/opt/conda/envs/mlflow-env/lib/python3.8/site-packages/mlflow/pyfunc/__init__.py\", line 755, in predict\n    return self._predict(data, params)\n  File \"/opt/conda/envs/mlflow-env/lib/python3.8/site-packages/mlflow/pyfunc/__init__.py\", line 793, in _predict\n    return self._predict_fn(data, params=params)\n  File \"/opt/conda/envs/mlflow-env/lib/python3.8/site-packages/mlflow/pyfunc/model.py\", line 642, in predict\n    return self.python_model.predict(self.context, self._convert_input(model_input))\n  File \"/home/spark-45e6e4c1-544c-4087-91cd-dd/.ipykernel/3327/command-1822611895488555-53800045\", line 42, in predict\n  File \"/home/spark-45e6e4c1-544c-4087-91cd-dd/.ipykernel/3327/command-1822611895488555-53800045\", line 22, in pre_process\n  File \"/home/spark-45e6e4c1-544c-4087-91cd-dd/.ipykernel/3327/command-1822611895488555-53800045\", line 23, in <listcomp>\nSystemError: /tmp/build/80754af9/python_1599203911753/work/Objects/listobject.c:353: bad argument to internal function\n"}
---------------------------------------------------------------------------
Exception                                 Traceback (most recent call last)
File <command-1822611895488580>, line 22
     18     return response.json()
     20 # Example usage
     21 # application_test = pd.read_csv('/Volumes/cat_ah01_dna_d_dlp_gen/ah_starbase_assessment/data/application_test.csv').head(1)
---> 22 predictions = score_model(application_test.head(1))
     23 predictions

File <command-1822611895488580>, line 17, in score_model(dataset)
     15 response = requests.request(method='POST', headers=headers, url=url, data=data_json)
     16 if response.status_code != 200:
---> 17     raise Exception(f'Request failed with status {response.status_code}, {response.text}')
     18 return response.json()

Exception: Request failed with status 400, {"error_code": "BAD_REQUEST", "message": "Encountered an unexpected error while evaluating the model. Verify that the input is compatible with the model for inference. Error '/tmp/build/80754af9/python_1599203911753/work/Objects/listobject.c:353: bad argument to internal function'", "stack_trace": "Traceback (most recent call last):\n  File \"/opt/conda/envs/mlflow-env/lib/python3.8/site-packages/mlflowserving/scoring_server/__init__.py\", line 676, in transformation\n    (raw_predictions, databricks_output, fs_metrics) = _score_model(\n  File \"/opt/conda/envs/mlflow-env/lib/python3.8/site-packages/mlflowserving/scoring_server/__init__.py\", line 431, in _score_model\n    prediction, fs_metrics = score_model_maybe_with_fs_metrics(model, data, params)\n  File \"/opt/conda/envs/mlflow-env/lib/python3.8/site-packages/mlflowserving/scoring_server/scoring_server_utils.py\", line 595, in score_model_maybe_with_fs_metrics\n    return (score_pyfunc_model(model, data, params), None)\n  File \"/opt/conda/envs/mlflow-env/lib/python3.8/site-packages/mlflowserving/scoring_server/scoring_server_utils.py\", line 600, in score_pyfunc_model\n    return model.predict(data, params=params)\n  File \"/opt/conda/envs/mlflow-env/lib/python3.8/site-packages/mlflow/pyfunc/__init__.py\", line 755, in predict\n    return self._predict(data, params)\n  File \"/opt/conda/envs/mlflow-env/lib/python3.8/site-packages/mlflow/pyfunc/__init__.py\", line 793, in _predict\n    return self._predict_fn(data, params=params)\n  File \"/opt/conda/envs/mlflow-env/lib/python3.8/site-packages/mlflow/pyfunc/model.py\", line 642, in predict\n    return self.python_model.predict(self.context, self._convert_input(model_input))\n  File \"/home/spark-45e6e4c1-544c-4087-91cd-dd/.ipykernel/3327/command-1822611895488555-53800045\", line 42, in predict\n  File \"/home/spark-45e6e4c1-544c-4087-91cd-dd/.ipykernel/3327/command-1822611895488555-53800045\", line 22, in pre_process\n  File \"/home/spark-45e6e4c1-544c-4087-91cd-dd/.ipykernel/3327/command-1822611895488555-53800045\", line 23, in <listcomp>\nSystemError: /tmp/build/80754af9/python_1599203911753/work/Objects/listobject.c:353: bad argument to internal function\n"}


import mlflow
import numpy as np
import json
import pandas as pd
import warnings
warnings.filterwarnings('ignore')
import mlflow
from mlflow.models.signature import infer_signature
from sklearn.preprocessing import LabelEncoder, PolynomialFeatures, MinMaxScaler
from sklearn.impute import SimpleImputer
from mlflow.models.signature import infer_signature

mlflow.set_registry_uri("databricks-uc")

model = mlflow.pyfunc.load_model(f'models:/cat_ah01_dna_d_dlp_gen.ah_starbase_assessment.lightgbm/5')
loaded_le_flag_own_car = mlflow.sklearn.load_model(f'models:/cat_ah01_dna_d_dlp_gen.ah_starbase_assessment.label_encoder_flag_own_car/5')
loaded_le_flag_own_realty = mlflow.sklearn.load_model(f'models:/cat_ah01_dna_d_dlp_gen.ah_starbase_assessment.label_encoder_flag_own_realty/5')
loaded_le_name_contract_type = mlflow.sklearn.load_model(f'models:/cat_ah01_dna_d_dlp_gen.ah_starbase_assessment.label_encoder_name_contract_type/5')
with open("/Workspace/Repos/ahstaff458@aia.com/atc_databricks_assessment/application_train_features.txt", 'r') as f:
    features_list = f.read().splitlines()
imputer_model_name = f'cat_ah01_dna_d_dlp_gen.ah_starbase_assessment.imputer'
imputer = mlflow.sklearn.load_model(f'models:/{imputer_model_name}/5')
scaler_model_name = f'cat_ah01_dna_d_dlp_gen.ah_starbase_assessment.scaler'
scaler = mlflow.sklearn.load_model(f'models:/{scaler_model_name}/5')


class CustomModel(mlflow.pyfunc.PythonModel):
    def __init__(self, model,loaded_le_flag_own_car,loaded_le_flag_own_realty,loaded_le_name_contract_type,features_list,imputer,scaler):
        # Load Models
        self.model = model
        self.loaded_le_flag_own_car = loaded_le_flag_own_car
        self.loaded_le_flag_own_realty = loaded_le_flag_own_realty
        self.loaded_le_name_contract_type = loaded_le_name_contract_type
        self.features_list = features_list
        self.imputer = imputer
        self.scaler = scaler 

    def load_context(self, context):
        self.context = context                       

    def pre_process(self, model_input):
        # Label Encode categorical variables
        model_input['FLAG_OWN_CAR'] = self.loaded_le_flag_own_car.transform(model_input['FLAG_OWN_CAR'])
        model_input['FLAG_OWN_REALTY'] = self.loaded_le_flag_own_realty.transform(model_input['FLAG_OWN_REALTY'])
        model_input['NAME_CONTRACT_TYPE'] = self.loaded_le_name_contract_type.transform(model_input['NAME_CONTRACT_TYPE'])
                
        # One hot Encode categorical variables
        model_input = pd.get_dummies(model_input)
        features_list = [feature for feature in self.features_list if feature != 'TARGET']
        model_input = model_input.reindex(columns=features_list, fill_value=0)

        # Preproces
        model_input['DAYS_EMPLOYED_ANOM'] = model_input["DAYS_EMPLOYED"] == 365243
        model_input["DAYS_EMPLOYED"].replace({365243: np.nan}, inplace = True)
        model_input['DAYS_BIRTH'] = abs(model_input['DAYS_BIRTH'])
        model_input = self.imputer.transform(model_input)
        model_input = self.scaler.transform(model_input)
        
        return model_input

    def predict(self, context, model_input:pd.DataFrame):
        # if isinstance(model_input, dict) and "columns" in model_input and "data" in model_input:
        #     model_input = pd.DataFrame(model_input["data"], columns=model_input["columns"])
        # elif not isinstance(model_input, pd.DataFrame):
        #     raise ValueError("Input must be a pandas DataFrame or a dictionary with 'columns' and 'data' keys.")

        # Add preprocessing step
        model_input = pd.DataFrame(model_input)
        model_input = self.pre_process(model_input)
        return self.model.predict(model_input).tolist()
    

    
# log_reg_model_name = f'models:/cat_ah01_dna_d_dlp_gen.ah_starbase_assessment.lightgbm/5'
# signature = infer_signature(application_train.drop('TARGET', axis=1), application_train['TARGET'])

lgbm_model_name = f'cat_ah01_dna_d_dlp_gen.ah_starbase_assessment.lightgbm_inference'
application_train = pd.read_csv('/Volumes/cat_ah01_dna_d_dlp_gen/ah_starbase_assessment/data/application_train.csv')

# Log the model with MLflow
with mlflow.start_run(run_name='lightgbm_custom_inference') as run:
    mlflow.pyfunc.log_model(
        registered_model_name=lgbm_model_name,
        artifact_path="lightgbm_custom",
        python_model=CustomModel(model,loaded_le_flag_own_car,loaded_le_flag_own_realty,loaded_le_name_contract_type,features_list,imputer,scaler),
        # signature=signature,
        input_example=application_train.drop('TARGET', axis=1).head(10).reset_index(drop=True).to_dict(orient='records'),
        conda_env={
            'channels': ['defaults'],
            'dependencies': [
                'python=3.8.5',
                'pip',
                {
                    'pip': [
                        'mlflow',
                        'numpy',
                        'pandas',
                        'scikit-learn',
                        'lightgbm'
                    ],
                },
            ],
        },
    )


import os
import requests
import numpy as np
import pandas as pd
import json

def create_tf_serving_json(data):
    return {'inputs': {name: data[name].tolist() for name in data.keys()} if isinstance(data, dict) else data.tolist()}

def score_model(dataset):
    url = 'https://adb-6515920204052091.11.azuredatabricks.net/serving-endpoints/custom_model/invocations'
    headers = {'Authorization': f'Bearer {token}', 'Content-Type': 'application/json'}
    ds_dict = {'dataframe_split': dataset.to_dict(orient='split')} if isinstance(dataset, pd.DataFrame) else create_tf_serving_json(dataset)
    data_json = json.dumps(ds_dict, allow_nan=True)
    response = requests.request(method='POST', headers=headers, url=url, data=data_json)
    if response.status_code != 200:
        raise Exception(f'Request failed with status {response.status_code}, {response.text}')
    return response.json()

# Example usage
# application_test = pd.read_csv('/Volumes/cat_ah01_dna_d_dlp_gen/ah_starbase_assessment/data/application_test.csv').head(1)
predictions = score_model(application_test.head(1))
predictions




### **Databricks Feature Store: Overview**

The **Databricks Feature Store** is a centralized repository for storing, sharing, and managing machine learning features. It is tightly integrated with Databricks workflows, including Delta Lake, MLflow, and Spark, and is designed to promote **feature reuse, reproducibility, and governance** in ML pipelines.

A feature store helps solve common challenges in machine learning, such as:
- Feature duplication across models.
- Lack of consistency between training and serving features.
- Difficulties tracking feature lineage and governance.

---

### **Key Features of Databricks Feature Store**

#### **1. Centralized Feature Repository**
- Provides a **centralized location** to store and manage features used across multiple ML models.
- Features can be stored as **feature tables**, which are versioned and organized in a Delta Lake-backed structure.

#### **2. Consistent Feature Engineering**
- Ensures **consistent feature computation** across training and inference pipelines.
- Allows developers to define features once and reuse them in multiple ML workflows.

#### **3. Online and Offline Feature Serving**
- **Offline Serving**: Features can be read directly during batch training or inference jobs.
- **Online Serving**: Low-latency feature retrieval via integration with online databases (e.g., AWS DynamoDB or Azure Cosmos DB) for real-time inference.

#### **4. Native Integration with Databricks Ecosystem**
- Fully integrated with **Delta Lake** for versioned feature storage and reliability.
- Works seamlessly with **MLflow**, enabling feature metadata tracking and linking features to registered models.

#### **5. Feature Lineage and Governance**
- Tracks feature **lineage** from the source data to feature generation and usage in models.
- Helps in understanding how features were derived and ensures compliance with governance requirements.

#### **6. Automatic Feature Versioning**
- Features are versioned automatically whenever updates are made, ensuring reproducibility in ML experiments.
- Allows rollbacks to previous versions of features if needed.

#### **7. Sharing and Reuse**
- Facilitates **feature reuse** across teams and projects, reducing redundancy and development time.
- Features can be accessed by multiple models, enabling collaboration.

#### **8. Real-Time Feature Engineering**
- Supports the creation of real-time features using event-based architectures and streaming data.

#### **9. Model Training and Scoring Integration**
- Automatically joins features with labels during model training.
- Provides APIs for scoring models by retrieving features from the feature store.

#### **10. Monitoring and Drift Detection**
- Provides tools to monitor feature usage and detect **feature drift** over time, ensuring model reliability.

---

### **Core Components of Databricks Feature Store**

1. **Feature Table**
   - A structured table that contains features, their metadata, and lineage.
   - Stored as Delta tables in Unity Catalog or a Databricks-managed metastore.
   - Example: A feature table for customer behavior:
     ```plaintext
     customer_id | avg_purchase_amount | total_orders | last_purchase_date
     ```

2. **Feature Store APIs**
   - Python and Scala APIs for creating, managing, and retrieving features.
   - Example:
     ```python
     from databricks.feature_store import FeatureStoreClient
     fs = FeatureStoreClient()

     # Create a feature table
     fs.create_table(
         name="main_catalog.customer_features",
         primary_keys=["customer_id"],
         schema=feature_schema,
         description="Features for customer segmentation"
     )
     ```

3. **Feature Serving Infrastructure**
   - Connects feature tables to training pipelines, batch scoring, and real-time serving systems.
   - Online serving supports low-latency use cases.

---

### **Steps to Use the Databricks Feature Store**

#### **1. Create a Feature Table**
- Define features using a Spark DataFrame or Delta Table and save them in the feature store.

```python
from databricks.feature_store import FeatureStoreClient

fs = FeatureStoreClient()

# Define features
customer_features = spark.sql("""
SELECT
    customer_id,
    AVG(purchase_amount) AS avg_purchase_amount,
    COUNT(order_id) AS total_orders
FROM
    sales_data
GROUP BY
    customer_id
""")

# Create or update the feature table
fs.create_table(
    name="main_catalog.sales.customer_features",
    primary_keys=["customer_id"],
    df=customer_features,
    description="Customer behavioral features"
)
```

#### **2. Use Features for Training**
- Retrieve features from the feature store and join them with labels for training.

```python
# Retrieve features
features = fs.read_table("main_catalog.sales.customer_features")

# Join features with labels
training_data = features.join(labels, on="customer_id")

# Train the model
from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier().fit(training_data[features], training_data["label"])
```

#### **3. Serve Features for Inference**
- Retrieve features in real-time or batch mode for inference.

**Batch Inference:**
```python
scored_data = fs.score_batch(
    model_uri="runs:/<run-id>/model",
    feature_table="main_catalog.sales.customer_features",
    result_table="main_catalog.sales.scored_data"
)
```

**Real-Time Inference:**
- Configure the feature store to serve features online using DynamoDB, CosmosDB, or other online stores.

---

### **Key Benefits of Databricks Feature Store**

1. **Reproducibility**:
   - Versioning ensures the same features are used during training and serving.

2. **Collaboration**:
   - Encourages feature sharing across teams, reducing development time and duplication.

3. **Performance**:
   - Efficient retrieval of features for both offline and online use cases.

4. **Scalability**:
   - Built on Delta Lake, enabling it to handle large-scale datasets and real-time data.

---

### **Limitations of Databricks Feature Store**

1. **Real-Time Serving Dependencies**:
   - Requires integration with external online storage systems like DynamoDB for real-time use cases.

2. **Cloud Dependency**:
   - Heavily dependent on Databricks and cloud infrastructure.

3. **Limited Non-Spark Integration**:
   - Designed for Spark-based environments, which may be restrictive for teams using other tools.

4. **Complexity for Small Workflows**:
   - Setting up a feature store may be overkill for small or simple ML projects.

---

### **Use Cases for Databricks Feature Store**

1. **Customer Personalization**:
   - Reuse behavioral features like purchase history, website visits, and interactions across multiple personalization models.

2. **Fraud Detection**:
   - Create real-time features based on transaction patterns and reuse them in fraud detection models.

3. **Predictive Maintenance**:
   - Store historical sensor data and derived features for equipment failure prediction models.

4. **Recommendation Systems**:
   - Build and reuse features for collaborative filtering and content-based recommendation engines.

---

If you'd like more details on any specific use case or example, feel free to ask!
